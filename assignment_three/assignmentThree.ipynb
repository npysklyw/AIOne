{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLESIZE = 500\n",
    "TESTSIZE = 0.90\n",
    "VALSIZE = 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming with Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data One "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small, y_small = make_circles(n_samples=(int(SAMPLESIZE/2),int(SAMPLESIZE/2)), random_state=3, \n",
    "noise=0.04, factor = 0.3)\n",
    "X_large, y_large = make_circles(n_samples=(int(SAMPLESIZE/2),int(SAMPLESIZE/2)), random_state=3, \n",
    "noise=0.04, factor = 0.7)\n",
    "y_large[y_large==1] = 2\n",
    "\n",
    "df = pd.DataFrame(np.vstack([X_small,X_large]),columns=['x1','x2'])\n",
    "df['labels'] = np.hstack([y_small,y_large])\n",
    "dfOne = shuffle(df)\n",
    "trainOne, valTestOne = train_test_split(dfOne, test_size=TESTSIZE)\n",
    "valone, testOne = train_test_split(valTestOne, test_size=VALSIZE)\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df,x='x1',y='x2',hue='labels',palette=\"bright\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data Five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "size = int(SAMPLESIZE/4)\n",
    "\n",
    "X.extend(list(np.random.uniform(low=10, high=50, size=(size,))))\n",
    "y.extend(list(np.random.uniform(low=48, high=50, size=(size,))))\n",
    "c = list(np.zeros(size))\n",
    "\n",
    "X.extend(list(np.random.uniform(low=25, high=35, size=(size,))))\n",
    "y.extend(list(np.random.uniform(low=23, high=25, size=(size,))))\n",
    "c.extend(np.ones(size))\n",
    "\n",
    "X.extend(list(np.random.uniform(low=10, high=50, size=(size,))))\n",
    "y.extend(list(np.random.uniform(low=33, high=35, size=(size,))))\n",
    "c.extend(np.ones(size)*2)\n",
    "\n",
    "X.extend(list(np.random.uniform(low=25, high=35, size=(size,))) )\n",
    "y.extend(list(np.random.uniform(low=43, high=45, size=(size,))))\n",
    "c.extend(np.ones(size)*3)\n",
    "\n",
    "\n",
    "dfTwo = pd.DataFrame(data={'x1': X, 'x2': y,'labels':c})\n",
    "dfTwo = shuffle(dfTwo)\n",
    "\n",
    "trainTwo, valTestTwo = train_test_split(dfTwo, test_size=TESTSIZE)\n",
    "valTwo, testTwo = train_test_split(valTestTwo, test_size=VALSIZE)\n",
    "sns.scatterplot(data=dfTwo,x='x1',y='x2',hue='labels')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data Six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(SAMPLESIZE/3)\n",
    "print(size)\n",
    "X,y = make_circles(n_samples=(size*2), random_state=3, \n",
    "noise=0.04, factor = 0.3)\n",
    "\n",
    "X1 = list(X[:, 0].flatten()*50)\n",
    "X2 = list(X[:, 1].flatten()*50)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "for x in range(0,len(X1)):\n",
    "\n",
    "    if ((((X1[x] > -20) and (X1[x] < 20))) and (((X2[x] > -20) and (X2[x] < 20)))):\n",
    "        n=1\n",
    "    else:\n",
    "        X.append(X1[x])\n",
    "        y.append(X2[x])\n",
    "        \n",
    "Xc = list(np.zeros(len(X)))\n",
    "Xc.pop\n",
    "X.extend(list(np.random.uniform(low=-5, high=5, size=(size,))))\n",
    "y.extend(list(np.random.uniform(low=-37, high=-30, size=(size,))))\n",
    "Xc.extend(list(np.ones(size)))\n",
    "\n",
    "X.extend(list(np.random.uniform(low=-5, high=5, size=(size,))))\n",
    "y.extend(list(np.random.uniform(low=30, high=37, size=(size,))))\n",
    "Xc.extend(list(np.ones(size)*2))\n",
    "\n",
    "print(len( X))\n",
    "print(len( y))\n",
    "print(len( Xc))\n",
    "dfThree= pd.DataFrame(data={'x1': X, 'x2': y,'labels':Xc})\n",
    "sns.scatterplot(data=dfThree,x='x1',y='x2',hue='labels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfThree = shuffle(dfThree)\n",
    "\n",
    "trainThree, valTestThree = train_test_split(dfThree, test_size=TESTSIZE)\n",
    "valThree, testThree = train_test_split(valTestThree, test_size=VALSIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Programmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN implementation\n",
    "def KNN(X,y,k,labels,Xtest,ytest):\n",
    "\n",
    "    X = list(X)\n",
    "    y = list(y)\n",
    "    Xtest = list(Xtest)\n",
    "    ytest= list(ytest)\n",
    "    labels = list(labels)\n",
    "\n",
    "    d = OrderedDict()\n",
    "    preds = {}\n",
    "\n",
    "    #Go through test examples\n",
    "    for index in range(0,len(Xtest)):\n",
    "\n",
    "        #Go through train examples \n",
    "        for index2 in range(0,len(X)):\n",
    "\n",
    "            #Ensure not same value\n",
    "            if (index2 != index):\n",
    "\n",
    "                #Compute eucledian distance - save this value to a dictionary with index\n",
    "                d[str(index2)] = np.sqrt((Xtest[index]- X[index2])**2 + (ytest[index] - y[index2])**2)\n",
    "\n",
    "        #Sort the eucledian distances\n",
    "        sortedDistances = dict(sorted(d.items(), key=lambda item: item[1]))\n",
    "\n",
    "\n",
    "        votes = []\n",
    "\n",
    "        #Look at K nearest neighbor labels that are in the training data\n",
    "        #Collect K nearest labels\n",
    "        for number in range(0,k):\n",
    "            votes.append(labels[int(list(sortedDistances.keys())[number])])\n",
    "        \n",
    "        #Set the label to the most \"voted\" label\n",
    "        preds[str(index)] = Counter(votes).most_common(1)[0][0]\n",
    "    return preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manually coded accuracy function\n",
    "def checkAccuracy(pred,test):\n",
    "    wrong = 0\n",
    "\n",
    "    for idx in range(len(pred)):\n",
    "        if (pred[idx] != test[idx]):\n",
    "            wrong = wrong + 1\n",
    "    return 1- wrong/len(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check for best k value in an array of different k values for KNN\n",
    "def bestK(dfTrain,dfTest):\n",
    "\n",
    "\n",
    "    k = [1,3,5,7,9]\n",
    "    accuracies = []\n",
    "\n",
    "    #Try each k value\n",
    "    for x in k:\n",
    "\n",
    "        #Predict labels with KNN with the K \n",
    "        predicted = KNN(dfTrain.x1,dfTrain.x2,x,dfTrain.labels,dfTest.x1,dfTest.x2)\n",
    "\n",
    "        #Save accuracy of this prediction\n",
    "        accuracies.append(checkAccuracy(list(predicted.values()),list(dfTest.labels)))\n",
    "\n",
    "\n",
    "    print(\"Best K: \", k[np.argmax(accuracies)])\n",
    "\n",
    "    #Return the K value that gives the best accuracy tested\n",
    "    return k[np.argmax(accuracies)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNAccuracy(train,valid,test):\n",
    "\n",
    "    k = bestK(train,valid)\n",
    "    predicted = KNN(train.x1,train.x2,k,train.labels,valid.x1,valid.x2)\n",
    "    print(\"\\nValidation Accuracy\", checkAccuracy(list(predicted.values()),list(valid.labels)))\n",
    "    predicted = KNN(train.x1,train.x2,k,train.labels,test.x1,test.x2)\n",
    "    print(\"Test Accuracy\", checkAccuracy(list(predicted.values()),list(test.labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset One\")\n",
    "KNNAccuracy(trainOne,valone,testOne)\n",
    "\n",
    "print(\"\\nDataset Two\")\n",
    "KNNAccuracy(trainTwo,valTwo,testTwo)\n",
    "\n",
    "print(\"\\nDataset Three\")\n",
    "KNNAccuracy(trainThree,valThree,testThree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of K-NN and Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Decision Tree with Existing Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to return accuracy of decision tree on data\n",
    "def decisionTree(train,val,test):\n",
    "\n",
    "    #Create decision tree\n",
    "    clf = DecisionTreeClassifier(max_depth = 2)\n",
    "    clf.fit(X=np.array(train.x1,train.x2).reshape(-1, 1),y=np.array(train.labels).reshape(-1, 1))\n",
    "\n",
    "    y_pred = clf.predict(np.array(val.x1,val.x2).reshape(-1, 1))\n",
    "    print(\"Validation Accuracy\", accuracy_score(np.array(val.labels).reshape(-1, 1), y_pred))\n",
    "\n",
    "    y_pred = clf.predict(np.array(test.x1,test.x2).reshape(-1, 1))\n",
    "    print(\"Test Accuracy\",accuracy_score(np.array(test.labels).reshape(-1, 1), y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree on Data vs K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset One\")\n",
    "print(\"\\nDecision Tree\")\n",
    "decisionTree(trainOne,valone,testOne)\n",
    "\n",
    "print(\"\\nKNN\")\n",
    "KNNAccuracy(trainOne,valone,testOne)\n",
    "\n",
    "print(\"\\nDataset Two\")\n",
    "print(\"\\nDecision Tree\")\n",
    "decisionTree(trainTwo,valTwo,testTwo)\n",
    "\n",
    "print(\"\\nKNN\")\n",
    "KNNAccuracy(trainTwo,valTwo,testTwo)\n",
    "\n",
    "print(\"\\nDataset Three\")\n",
    "print(\"\\nDecision Tree\")\n",
    "decisionTree(trainThree,valThree,testThree)\n",
    "\n",
    "print(\"\\nKNN\")\n",
    "KNNAccuracy(trainThree,valThree,testThree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModelOne(trainData,valData,testData):\n",
    "\n",
    "    enc = OneHotEncoder()\n",
    "    labels = np.array(trainData.labels).reshape(-1, 1)\n",
    "    enc.fit(labels)  \n",
    "    ytrain = enc.transform(labels).toarray()\n",
    "    Xtrain = np.array([trainData.x1,trainData.x2]).T\n",
    "    Xtest = np.array([testData.x1,testData.x2]).T\n",
    "    XVal = np.array([valData.x1,valData.x2]).T\n",
    "\n",
    "    encTwo = OneHotEncoder()\n",
    "    labels = np.array(testData.labels).reshape(-1, 1)\n",
    "    encTwo.fit(labels)  \n",
    "    ytest = encTwo.transform(labels).toarray()\n",
    "\n",
    "    \n",
    "    encThree = OneHotEncoder()\n",
    "    labels = np.array(valData.labels).reshape(-1, 1)\n",
    "    encThree.fit(labels)  \n",
    "    yval = encThree.transform(labels).toarray()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_shape=(2,), activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(len(ytrain[0]), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(Xtrain, ytrain, epochs=160, batch_size=10,verbose=0)\n",
    "\n",
    "    _, accuracy = model.evaluate(XVal, yval)\n",
    "    print('Validation Accuracy: %.2f' % (accuracy*100))    \n",
    "\n",
    "    _, accuracy = model.evaluate(Xtest, ytest)\n",
    "    print('Test Accuracy: %.2f' % (accuracy*100))    \n",
    "    \n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModelTwo(trainData,valData,testData):\n",
    "\n",
    "    enc = OneHotEncoder()\n",
    "    labels = np.array(trainData.labels).reshape(-1, 1)\n",
    "    enc.fit(labels)  \n",
    "    ytrain = enc.transform(labels).toarray()\n",
    "    Xtrain = np.array([trainData.x1,trainData.x2]).T\n",
    "    Xtest = np.array([testData.x1,testData.x2]).T\n",
    "    XVal = np.array([valData.x1,valData.x2]).T\n",
    "\n",
    "    encTwo = OneHotEncoder()\n",
    "    labels = np.array(testData.labels).reshape(-1, 1)\n",
    "    encTwo.fit(labels)  \n",
    "    ytest = encTwo.transform(labels).toarray()\n",
    "\n",
    "    \n",
    "    encThree = OneHotEncoder()\n",
    "    labels = np.array(valData.labels).reshape(-1, 1)\n",
    "    encThree.fit(labels)  \n",
    "    yval = encThree.transform(labels).toarray()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_shape=(2,), activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))  \n",
    "    model.add(Dense(8, activation='relu'))  \n",
    "    model.add(Dense(len(ytrain[0]), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(Xtrain, ytrain, epochs=160, batch_size=10,verbose=0)\n",
    "\n",
    "    _, accuracy = model.evaluate(XVal, yval)\n",
    "    print('Validation Accuracy: %.2f' % (accuracy*100))    \n",
    "\n",
    "    _, accuracy = model.evaluate(Xtest, ytest)\n",
    "    print('Test Accuracy: %.2f' % (accuracy*100))    \n",
    "    \n",
    "    #plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Networks Performance on Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runModelOne(trainOne,valone, testOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runModelOne(trainTwo,valTwo,testTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runModelOne(trainThree,valThree,testThree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runModelTwo(trainOne,valone, testOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runModelTwo(trainTwo,valTwo,testTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runModelTwo(trainThree,valThree,testThree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Noise Levels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to create Gaussian noise here. I define a function to generate a % of gaussian noise on some data and return noisyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisySet(data,noiseLevel):\n",
    "    guess = np.array([data.x1,data.x2])\n",
    "\n",
    "    noise = np.random.normal(1,noiseLevel, guess.shape)\n",
    "    new_signal = guess + noise\n",
    "\n",
    "    # plt.scatter(new_signal[0],new_signal[1],c=data.labels)\n",
    "    new_signal = pd.DataFrame(data={'x1': new_signal[0], 'x2':  new_signal[1],'labels':data.labels})\n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data for One and Two + Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per dataset, do 5%, 10%, 20%, and 25% noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to generate noisy train,val,test data then run a decision tree + KNN on these\n",
    "def noiseDataModel(train,val,test,noise):\n",
    "\n",
    "    \n",
    "    for types in noise: \n",
    "        noiseTrain= noisySet(train,types)\n",
    "        noiseVal = noisySet(val,types)\n",
    "        noiseTest = noisySet(test,types)\n",
    "\n",
    "        print(\"\\nNoise Level:\", (float(types)*99))\n",
    "        print(\"\\nDecision Tree\")\n",
    "        decisionTree(noiseTrain,noiseVal,noiseTest)\n",
    "    \n",
    "        print(\"\\nKNN\")\n",
    "        KNNAccuracy(noiseTrain,noiseVal,noiseTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset One\n",
      "\n",
      "Noise Level: 4.95\n",
      "\n",
      "Decision Tree\n",
      "Validation Accuracy 0.6111111111111112\n",
      "Test Accuracy 0.5238095238095238\n",
      "\n",
      "KNN\n",
      "Best K:  1\n",
      "\n",
      "Validation Accuracy 0.9518518518518518\n",
      "Test Accuracy 0.9587301587301588\n",
      "\n",
      "Noise Level: 9.9\n",
      "\n",
      "Decision Tree\n",
      "Validation Accuracy 0.5037037037037037\n",
      "Test Accuracy 0.4857142857142857\n",
      "\n",
      "KNN\n",
      "Best K:  3\n",
      "\n",
      "Validation Accuracy 0.8777777777777778\n",
      "Test Accuracy 0.8380952380952381\n",
      "\n",
      "Noise Level: 19.8\n",
      "\n",
      "Decision Tree\n",
      "Validation Accuracy 0.5037037037037037\n",
      "Test Accuracy 0.4857142857142857\n",
      "\n",
      "KNN\n",
      "Best K:  7\n",
      "\n",
      "Validation Accuracy 0.7592592592592593\n",
      "Test Accuracy 0.7158730158730159\n",
      "\n",
      "Noise Level: 24.75\n",
      "\n",
      "Decision Tree\n",
      "Validation Accuracy 0.5037037037037037\n",
      "Test Accuracy 0.4857142857142857\n",
      "\n",
      "KNN\n",
      "Best K:  7\n",
      "\n",
      "Validation Accuracy 0.7037037037037037\n",
      "Test Accuracy 0.6650793650793652\n"
     ]
    }
   ],
   "source": [
    "#Define the noise levels we want\n",
    "noiseLevels = [0.05,0.10,0.20,0.25]\n",
    "\n",
    "print(\"Dataset One\")\n",
    "noiseDataModel(trainOne,valone,testOne,noiseLevels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Two\n",
      "\n",
      "Noise Level: 49.5\n",
      "\n",
      "Decision Tree\n",
      "Validation Accuracy 0.4074074074074074\n",
      "Test Accuracy 0.37142857142857144\n",
      "\n",
      "KNN\n",
      "Best K:  1\n",
      "\n",
      "Validation Accuracy 0.9925925925925926\n",
      "Test Accuracy 0.9936507936507937\n",
      "\n",
      "Noise Level: 99.0\n",
      "\n",
      "Decision Tree\n",
      "Validation Accuracy 0.4444444444444444\n",
      "Test Accuracy 0.4095238095238095\n",
      "\n",
      "KNN\n",
      "Best K:  1\n",
      "\n",
      "Validation Accuracy 0.9777777777777777\n",
      "Test Accuracy 0.9873015873015873\n",
      "\n",
      "Noise Level: 198.0\n",
      "\n",
      "Decision Tree\n",
      "Validation Accuracy 0.3851851851851852\n",
      "Test Accuracy 0.3873015873015873\n",
      "\n",
      "KNN\n",
      "Best K:  5\n",
      "\n",
      "Validation Accuracy 0.8666666666666667\n",
      "Test Accuracy 0.9015873015873016\n",
      "\n",
      "Noise Level: 247.5\n",
      "\n",
      "Decision Tree\n",
      "Validation Accuracy 0.4\n",
      "Test Accuracy 0.37777777777777777\n",
      "\n",
      "KNN\n",
      "Best K:  3\n",
      "\n",
      "Validation Accuracy 0.8666666666666667\n",
      "Test Accuracy 0.8857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Two\")\n",
    "factoredUpNoise = [x * 10 for x in noiseLevels]\n",
    "noiseDataModel(trainTwo,valTwo,testTwo,factoredUpNoise)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0d12b61020dce22a16154c9edda0fe2d4d34d22ccbcb4c7b1d1a377450f976d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
